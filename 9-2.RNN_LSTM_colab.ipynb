{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "9-2.RNN_LSTM.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "WHozbnR01pDy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## RNN 실습\n",
        "- RNN MNIST 분류기\n",
        "- RNN 주가예측(Regression)\n",
        "- RNN 문장만들어내기 (charRNN)"
      ]
    },
    {
      "metadata": {
        "id": "VKvxIwOj1xgd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Junhojuno/DeepLearning-Beginning/blob/master/9-2.RNN_LSTM.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "1OXUz1mk1pD1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. MNIST Classifier\n",
        "- 28x28 image에서 28개의 벡터가 28번 순차적으로 들어간다고 하고 마지막 28번째 벡터가 들어오면 분류가 되는 형태로 진행"
      ]
    },
    {
      "metadata": {
        "id": "554UMUxZ1pD2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "9861c1dd-0a59-4d1c-b674-24d4d9bc94e6"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
        "import tensorflow.contrib.rnn as rnn\n",
        "mnist = input_data.read_data_sets(\"data/\", one_hot=True)\n",
        "print(\"PACKAGE LOADED\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting data/train-images-idx3-ubyte.gz\n",
            "Extracting data/train-labels-idx1-ubyte.gz\n",
            "Extracting data/t10k-images-idx3-ubyte.gz\n",
            "Extracting data/t10k-labels-idx1-ubyte.gz\n",
            "PACKAGE LOADED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CpjHKmQZ1pD-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainimgs, trainlabels, testimgs, testlabels \\\n",
        "    = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dhaY0X8Z1pED",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0cd8dec0-f77c-4bfc-8542-615976ed01c6"
      },
      "cell_type": "code",
      "source": [
        "ntrain = trainimgs.shape[0]\n",
        "ntest = testimgs.shape[0]\n",
        "dim = trainimgs.shape[1]\n",
        "nclasses = trainlabels.shape[1]\n",
        "\n",
        "print(\"MNIST LOADED.\")\n",
        "print(\"TF VERSION : %s\" % (tf.__version__))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MNIST LOADED.\n",
            "TF VERSION : 1.12.0-rc2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OXDYDxxv1pEH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**아래 그림과 같은 형태로 진행**"
      ]
    },
    {
      "metadata": {
        "id": "6TEFBKtv1pEI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![](https://github.com/Junhojuno/DeepLearning-Beginning/blob/master/NN_images/process.jpg?raw=1)"
      ]
    },
    {
      "metadata": {
        "id": "lMtQWfrN1pEJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define Model"
      ]
    },
    {
      "metadata": {
        "id": "G5EltM6d1pEK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "diminput = 28\n",
        "dimhidden = 128\n",
        "dimoutput = nclasses\n",
        "nsteps = 28\n",
        "weights = {\n",
        "   \n",
        "    # 28 dimension에서 128 dimension으로,\n",
        "    # 128 dimension에서 10 dimension으로 가는 weights를 잡아준다.\n",
        "    \n",
        "    'hidden': tf.Variable(initial_value=tf.random_normal([diminput, dimhidden])), \n",
        "    'out': tf.Variable(initial_value=tf.random_normal([dimhidden,dimoutput])),\n",
        "}\n",
        "biases = {\n",
        "    'hidden': tf.Variable(initial_value=tf.random_normal([dimhidden])),\n",
        "    'out': tf.Variable(initial_value=tf.random_normal([dimoutput])),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aQyjfjoX1pEN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define Function"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "wNLTUiT_1pEO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "323840b4-cf02-4330-e84e-d807dd29079e"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a = np.array([[[0,0,0],[1,1,1],[2,2,2],[3,3,3]],\n",
        "              [[4,4,4],[5,5,5],[6,6,6],[7,7,7]]])\n",
        "print(a.shape)\n",
        "a_hat = np.transpose(a, [1,0,2])\n",
        "print(a_hat.shape)\n",
        "\n",
        "a_hat = np.reshape(a_hat, (-1,3))\n",
        "print(a_hat.shape)\n",
        "a_split = np.split(a_hat, 4, axis=0)\n",
        "print(a_split)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 4, 3)\n",
            "(4, 2, 3)\n",
            "(8, 3)\n",
            "[array([[0, 0, 0],\n",
            "       [4, 4, 4]]), array([[1, 1, 1],\n",
            "       [5, 5, 5]]), array([[2, 2, 2],\n",
            "       [6, 6, 6]]), array([[3, 3, 3],\n",
            "       [7, 7, 7]])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WidwJY-n1pEU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![](https://github.com/Junhojuno/DeepLearning-Beginning/blob/master/NN_images/RNN.png?raw=1)"
      ]
    },
    {
      "metadata": {
        "id": "p1ZX9jbZ1pEV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1. Cell을 정의한다.(BasicRNNCell,BasicLSTMCell...) (Cell 생성)\n",
        "    - 위 그림에서 A 박스 부분이 Cell이라 보면 된다.\n",
        "    - 여기서 num_units는 hidden_size를 말하는데, 출력($h_{t}$)의 크기를 말한다.\n",
        "    \n",
        "\n",
        "2. Cell을 구동시켜서 입력을 주고 출력값을 뽑아내는 드라이버를 만든다.(Cell 구동)\n",
        "    - 드라이버로는 dynamic_rnn 등이 있고,\n",
        "    - 드라이버 입력값은 정의한 cell, 입력데이터($x_{t}$)순서!\n",
        "    - 이 드라이버의 출력값은 $h_{t}$와 state값이다."
      ]
    },
    {
      "metadata": {
        "id": "cl16abQa1pEX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a27d7175-9645-4ddf-c838-a37c099cd8b9"
      },
      "cell_type": "code",
      "source": [
        "def _RNN(_x, _istate, _w, _b, _nsteps, _name):\n",
        "    # 1. batch_sizex28x28 --> 28xbatch_sizex28로 바꿔준다.\n",
        "    _x = tf.transpose(_x, [1,0,2])\n",
        "    # 2. Reshape input : [nstep*batch_size, diminput]\n",
        "    _x = tf.reshape(_x, shape=[-1, diminput])\n",
        "    \n",
        "    # 3. Input to hidden layer\n",
        "    # 140x28 input과 28x128 weights의 행렬곱\n",
        "    # output : 140x128\n",
        "    _H = tf.matmul(_x, _w['hidden']) + _b['hidden']\n",
        "    # 4. Split Data to 'nstep(28)' chunks --> batch_size만큼 한묶음인 data의 List를 만들어주는 과정이다.\n",
        "    _Hsplit = tf.split(_H, _nsteps, axis=0)\n",
        "    \n",
        "    # 5. Get LSTM's Final output (_LSTM_O) and state (_LSTM_S)\n",
        "    with tf.variable_scope(_name):\n",
        "        # rnn = tf.contrib.rnn\n",
        "        # cell 정의\n",
        "        # Gate에 들어있는 neural net의 weight를 알아서 선언해줌\n",
        "        # 먼저 cell을 만들자(num_units는 output의 크기를 의미)\n",
        "        lstm_cell = rnn.BasicLSTMCell(num_units=dimhidden, forget_bias=1.0\n",
        "                                     , state_is_tuple=False)\n",
        "        # cell을 만들었으니 구동시키자\n",
        "        # parameter는 cell, 입력데이터 순서(x_t)이다.\n",
        "        # sequence length : 28\n",
        "        # 즉 A 박스가 28개가 있다는 얘기다.\n",
        "        _LSTM_O, _LSTM_S = rnn.static_rnn(lstm_cell, _Hsplit, initial_state=_istate)\n",
        "    \n",
        "    # Output\n",
        "    _o = tf.matmul(_LSTM_O[-1], _w['out']) + _b['out']\n",
        "    return {\n",
        "        'x': _x, 'H': _H, 'Hsplit': _Hsplit, 'LSTM_O': _LSTM_O, 'LSTM_S': _LSTM_S, \n",
        "        'o': _o \n",
        "    }\n",
        "print(\"Function Ready..!!\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Function Ready..!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J-cmj9Yq1pEb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define Graph"
      ]
    },
    {
      "metadata": {
        "id": "U9kbWts41pEb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "a3eeec28-cff5-4887-bae0-d8f09c83031d"
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "x = tf.placeholder('float', [None, nsteps, diminput])\n",
        "# state & cell = 2 * n_hidden\n",
        "istate = tf.placeholder('float', [None, 2*dimhidden]) # istate means initial state\n",
        "y = tf.placeholder('float', [None, dimoutput])\n",
        "\n",
        "myrnn = _RNN(x, istate, weights, biases, _nsteps=nsteps, _name='basic')\n",
        "pred = myrnn['o']\n",
        "\n",
        "# Cost and optimizer\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=y))\n",
        "optimize = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(pred,1), tf.argmax(y,1)), tf.float32))\n",
        "init = tf.global_variables_initializer()\n",
        "print(\"Network Ready..!!\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-11-74bf98fb1735>:21: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
            "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fb07892d748>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
            "Network Ready..!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Dkxqb9cP1pEf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Run"
      ]
    },
    {
      "metadata": {
        "id": "-46TxM6Y1pEh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_epochs = 5\n",
        "batch_size = 100\n",
        "display_step = 1\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth=True\n",
        "sess = tf.Session(config=config)\n",
        "sess.run(init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-k5-WY0S1pEl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**GPU가 없어서리...실행불가...**"
      ]
    },
    {
      "metadata": {
        "id": "y-6dy79y1pEm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Optimizer"
      ]
    },
    {
      "metadata": {
        "id": "xeYxnchx1pEn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "ccec7072-fa33-497d-b71b-3b7ff2860152"
      },
      "cell_type": "code",
      "source": [
        "print (\"START OPTIMIZATION.\")\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0.\n",
        "    total_batch = int(mnist.train.num_examples/batch_size)\n",
        "    # Loop over all batches\n",
        "    for i in range(total_batch):\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "        batch_xs = batch_xs.reshape((batch_size, nsteps, diminput))\n",
        "        # Fit training using batch data\n",
        "        feeds = {x: batch_xs, y: batch_ys, istate: np.zeros((batch_size, 2*dimhidden))}\n",
        "        sess.run(optimize, feed_dict=feeds)\n",
        "        # compute average loss\n",
        "        avg_cost += sess.run(cost, feed_dict=feeds)/total_batch\n",
        "    # Display logs per epoch step\n",
        "    if epoch % display_step == 0:\n",
        "        print(\"EPOCH: %03d/%03d COST: %.9f\" % (epoch, training_epochs, avg_cost))\n",
        "        feeds = {x:batch_xs, y: batch_ys, istate: np.zeros((batch_size, 2*dimhidden))}\n",
        "        train_acc = sess.run(accuracy, feed_dict=feeds)\n",
        "        print (\"TRAIN ACCURACY: %.3f\" % (train_acc))\n",
        "        testimgs = testimgs.reshape((ntest, nsteps, diminput))\n",
        "        feeds = {x: testimgs, y: testlabels, istate: np.zeros((ntest, 2*dimhidden))}\n",
        "        test_acc = sess.run(accuracy, feed_dict=feeds)\n",
        "        print (\" TEST ACCURACY : %.3f\" % (test_acc))\n",
        "print (\"OPTIMIZATION FINISHED.\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "START OPTIMIZATION.\n",
            "EPOCH: 000/005 COST: 0.431314853\n",
            "TRAIN ACCURACY: 0.910\n",
            " TEST ACCURACY : 0.942\n",
            "EPOCH: 001/005 COST: 0.116124308\n",
            "TRAIN ACCURACY: 0.990\n",
            " TEST ACCURACY : 0.961\n",
            "EPOCH: 002/005 COST: 0.075874198\n",
            "TRAIN ACCURACY: 0.990\n",
            " TEST ACCURACY : 0.970\n",
            "EPOCH: 003/005 COST: 0.053807406\n",
            "TRAIN ACCURACY: 1.000\n",
            " TEST ACCURACY : 0.973\n",
            "EPOCH: 004/005 COST: 0.045213481\n",
            "TRAIN ACCURACY: 0.990\n",
            " TEST ACCURACY : 0.978\n",
            "OPTIMIZATION FINISHED.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}