{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN 실습\n",
    "- RNN MNIST 분류기\n",
    "- RNN 주가예측(Regression)\n",
    "- RNN 문장만들어내기 (charRNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. MNIST Classifier\n",
    "- 28x28 image에서 28개의 벡터가 28번 순차적으로 들어간다고 하고 마지막 28번째 벡터가 들어오면 분류가 되는 형태로 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "PACKAGE LOADED\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "import tensorflow.contrib.rnn as rnn\n",
    "mnist = input_data.read_data_sets(\"data/\", one_hot=True)\n",
    "print(\"PACKAGE LOADED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainimgs, trainlabels, testimgs, testlabels \\\n",
    "    = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST LOADED.\n",
      "TF VERSION : 1.8.0\n"
     ]
    }
   ],
   "source": [
    "ntrain = trainimgs.shape[0]\n",
    "ntest = testimgs.shape[0]\n",
    "dim = trainimgs.shape[1]\n",
    "nclasses = trainlabels.shape[1]\n",
    "\n",
    "print(\"MNIST LOADED.\")\n",
    "print(\"TF VERSION : %s\" % (tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**아래 그림과 같은 형태로 진행**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./NN_images/process.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "diminput = 28\n",
    "dimhidden = 128\n",
    "dimoutput = nclasses\n",
    "nsteps = 28\n",
    "weights = {\n",
    "    \"\"\"\n",
    "    28 dimension에서 128 dimension으로,\n",
    "    128 dimension에서 10 dimension으로 가는 weights를 잡아준다.\n",
    "    \"\"\"\n",
    "    'hidden': tf.Variable(initial_value=tf.random_normal([diminput, dimhidden])), \n",
    "    'out': tf.Variable(initial_value=tf.random_normal([dimhidden,dimoutput])),\n",
    "}\n",
    "biases = {\n",
    "    'hidden': tf.Variable(initial_value=tf.random_normal([dimhidden])),\n",
    "    'out': tf.Variable(initial_value=tf.random_normal([dimoutput])),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4, 3)\n",
      "(4, 2, 3)\n",
      "(8, 3)\n",
      "[array([[0, 0, 0],\n",
      "       [4, 4, 4]]), array([[1, 1, 1],\n",
      "       [5, 5, 5]]), array([[2, 2, 2],\n",
      "       [6, 6, 6]]), array([[3, 3, 3],\n",
      "       [7, 7, 7]])]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[[0,0,0],[1,1,1],[2,2,2],[3,3,3]],\n",
    "              [[4,4,4],[5,5,5],[6,6,6],[7,7,7]]])\n",
    "print(a.shape)\n",
    "a_hat = np.transpose(a, [1,0,2])\n",
    "print(a_hat.shape)\n",
    "\n",
    "a_hat = np.reshape(a_hat, (-1,3))\n",
    "print(a_hat.shape)\n",
    "a_split = np.split(a_hat, 4, axis=0)\n",
    "print(a_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./NN_images/RNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Cell을 정의한다.(BasicRNNCell,BasicLSTMCell...) (Cell 생성)\n",
    "    - 위 그림에서 A 박스 부분이 Cell이라 보면 된다.\n",
    "    - 여기서 num_units는 hidden_size를 말하는데, 출력($h_{t}$)의 크기를 말한다.\n",
    "    \n",
    "\n",
    "2. Cell을 구동시켜서 입력을 주고 출력값을 뽑아내는 드라이버를 만든다.(Cell 구동)\n",
    "    - 드라이버로는 dynamic_rnn 등이 있고,\n",
    "    - 드라이버 입력값은 정의한 cell, 입력데이터($x_{t}$)순서!\n",
    "    - 이 드라이버의 출력값은 $h_{t}$와 state값이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Ready..!!\n"
     ]
    }
   ],
   "source": [
    "def _RNN(_x, _istate, _w, _b, _nsteps, _name):\n",
    "    # 1. batch_sizex28x28 --> 28xbatch_sizex28로 바꿔준다.\n",
    "    _x = tf.transpose(_x, [1,0,2])\n",
    "    # 2. Reshape input : [nstep*batch_size, diminput]\n",
    "    _x = tf.reshape(_x, shape=[-1, diminput])\n",
    "    \n",
    "    # 3. Input to hidden layer\n",
    "    # 140x28 input과 28x128 weights의 행렬곱\n",
    "    # output : 140x128\n",
    "    _H = tf.matmul(_x, _w['hidden']) + _b['hidden']\n",
    "    # 4. Split Data to 'nstep(28)' chunks --> batch_size만큼 한묶음인 data의 List를 만들어주는 과정이다.\n",
    "    _Hsplit = tf.split(_H, _nsteps, axis=0)\n",
    "    \n",
    "    # 5. Get LSTM's Final output (_LSTM_O) and state (_LSTM_S)\n",
    "    with tf.variable_scope(_name):\n",
    "        # rnn = tf.contrib.rnn\n",
    "        # cell 정의\n",
    "        # Gate에 들어있는 neural net의 weight를 알아서 선언해줌\n",
    "        # 먼저 cell을 만들자(num_units는 output의 크기를 의미)\n",
    "        lstm_cell = rnn.BasicLSTMCell(num_units=dimhidden, forget_bias=1.0\n",
    "                                     , state_is_tuple=False)\n",
    "        # cell을 만들었으니 구동시키자\n",
    "        # parameter는 cell, 입력데이터 순서(x_t)이다.\n",
    "        # sequence length : 28\n",
    "        # 즉 A 박스가 28개가 있다는 얘기다.\n",
    "        _LSTM_O, _LSTM_S = rnn.static_rnn(lstm_cell, _Hsplit, initial_state=_istate)\n",
    "    \n",
    "    # Output\n",
    "    _o = tf.matmul(_LSTM_O[-1], _w['out']) + _b['out']\n",
    "    return {\n",
    "        'x': _x, 'H': _H, 'Hsplit': _Hsplit, 'LSTM_O': _LSTM_O, 'LSTM_S': _LSTM_S, \n",
    "        'o': _o \n",
    "    }\n",
    "print(\"Function Ready..!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000001CB11C27F98>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "Network Ready..!!\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "x = tf.placeholder('float', [None, nsteps, diminput])\n",
    "# state & cell = 2 * n_hidden\n",
    "istate = tf.placeholder('float', [None, 2*dimhidden]) # istate means initial state\n",
    "y = tf.placeholder('float', [None, dimoutput])\n",
    "\n",
    "myrnn = _RNN(x, istate, weights, biases, _nsteps=nsteps, _name='basic')\n",
    "pred = myrnn['o']\n",
    "\n",
    "# Cost and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=y))\n",
    "optimize = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(pred,1), tf.argmax(y,1)), tf.float32))\n",
    "init = tf.global_variables_initializer()\n",
    "print(\"Network Ready..!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs = 5\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GPU가 없어서리...실행불가...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"START OPTIMIZATION.\")\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "    total_batch = ini(MNIST.train.num_examples/batch_size)\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = MNIST.train.next_batch(batch_size)\n",
    "        batch_xs = batch_xs.reshape((batch_size, nsteps, diminput))\n",
    "        # Fit training using batch data\n",
    "        feeds = {x: batch_xs, y: batch_ys, istate: np.zeros((batch_size, 2*dimhidden))}\n",
    "        sess.run(optm, feed_dict=feeds)\n",
    "        # compute average loss\n",
    "        avg_cost += sess.run(cost, feed_dict=feeds)/total_batch\n",
    "    # Display logs per epoch step\n",
    "    if epoch % display_step == 0:\n",
    "        print(\"EPOCH: %03d/%03d COST: %.9f\" % (epoch, training_epochs, avg_cost))\n",
    "        feeds = {x:batch_xs, y: batch_ys, istate: np.zeros((batch_size, 2*dimhidden))}\n",
    "        train_acc = sess.run(accr, feed_dict=feeds)\n",
    "        print (\"TRAIN ACCURACY: %.3f\" % (train_acc))\n",
    "        testimgs = testimgs.reshape((ntest, nsteps, diminput))\n",
    "        feeds = {x: testimgs, y: testlabels, istate: np.zeors((ntest, 2*dimhidden))}\n",
    "        test_acc = sess.run(accr, feed_dict=feeds)\n",
    "        print (\" TEST ACCURACY : %.3f\" % (test_acc))\n",
    "print (\"OPTIMIZATION FINISHED.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
