{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1.MLP_mnist_tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Junhojuno/DeepLearning-Beginning/blob/master/code_review/1.MLP_mnist_tensorflow_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "uMrL1jnP6oV-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "9f9e2372-6589-40a7-fded-b5fe98021c48"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xByUItre6oWM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3497d988-9238-472a-84e2-865be8900301"
      },
      "cell_type": "code",
      "source": [
        "# parameter setting\n",
        "n_input = 784 # 28 x 28 image,  input layer nodes\n",
        "n_hidden1 = 256 # the number of 1st hidden layer nodes\n",
        "n_hidden2 = 128 # the number of 2nd hidden layer nodes\n",
        "n_classes = 10 # 0~9 classification , output layer nodes\n",
        "\n",
        "# placeholder x, y that we input\n",
        "x = tf.placeholder(dtype=tf.float32, shape=[None, n_input]) # ?(batch size) x 784\n",
        "y = tf.placeholder(dtype=tf.float32, shape=[None, n_classes]) # ?(batch size) x 10\n",
        "\n",
        "# network parameter setting : weights & biases\n",
        "# weights는 inner product관점에서 생각해보면 이해할 수 있음.\n",
        "# biases는 각 layer의 node갯수\n",
        "# input : ? x 784\n",
        "weights = {\n",
        "    'h1' : tf.Variable(initial_value=tf.random_normal(shape=[n_input, n_hidden1], stddev=0.1)), # 784 x 256\n",
        "    'h2' : tf.Variable(initial_value=tf.random_normal(shape=[n_hidden1, n_hidden2], stddev=0.1)), # 256 x 128\n",
        "    'out' : tf.Variable(initial_value=tf.random_normal(shape=[n_hidden2, n_classes], stddev=0.1)) # 128 x 10\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'h1' : tf.Variable(initial_value=tf.random_normal(shape=[n_hidden1])), # 256\n",
        "    'h2' : tf.Variable(initial_value=tf.random_normal(shape=[n_hidden2])), # 128\n",
        "    'out' : tf.Variable(initial_value=tf.random_normal(shape=[n_classes])) # 10\n",
        "}\n",
        "\n",
        "print(\"parameter setting is completed\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "parameter setting is completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "h5bul93k6oWR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7cb6beb4-b962-4e1a-86f6-cea98c3bdf6d"
      },
      "cell_type": "code",
      "source": [
        "# define graph\n",
        "# 연산과 연산의 연결을 만든다.\n",
        "\n",
        "# model\n",
        "# 위에서 정의한 변수들을 고려하여, 실제 연산 network를 정의한다.\n",
        "# matrix product, add biases, activation function을 고려한다.\n",
        "def mlp(_x, _w, _b):\n",
        "    # tf.sigmoid = tf.nn.sigmoid : 둘의 차이는 없다고 한다.\n",
        "    hidden_layer1 = tf.nn.sigmoid(tf.add(tf.matmul(_x, _w['h1']),_b['h1']))\n",
        "    hidden_layer2 = tf.nn.sigmoid(tf.add(tf.matmul(hidden_layer1, _w['h2']),_b['h2']))\n",
        "    out = tf.add(tf.matmul(hidden_layer2, _w['out']), _b['out'])\n",
        "    return out # logit으로 출력\n",
        "\n",
        "# prediction\n",
        "prediction = mlp(x, weights, biases)\n",
        "\n",
        "# cost(loss) function, optimizer\n",
        "# loss : cross entropy\n",
        "# reduce_sum 까지는 데이터 하나당 loss\n",
        "# reduce_mean까지 보면 전체 데이터의 loss 평균\n",
        "# cost = -tf.reduce_mean(tf.reduce_sum(y * tf.log(prediction),axis=1))\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=prediction))\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
        "\n",
        "# accuracy check\n",
        "# tf.argmax는 가장큰 값의 인덱스 추출\n",
        "# 이게 맞으면 1, 틀리면 0 추출(tf.equal)\n",
        "# float로 type변경하여 정확도 출력(boolean type --> float type)\n",
        "correct = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct,dtype='float'))\n",
        "\n",
        "print(\"Graph ready..\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Graph ready..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8nXHGA1R6oWY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "1cef3902-2f33-4bb8-ec44-25f9bb1813ef"
      },
      "cell_type": "code",
      "source": [
        "# Training\n",
        "training_epochs = 20\n",
        "batch_size = 100\n",
        "display_step = 4\n",
        "\n",
        "# initialize\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "# optimizing\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    total_batch = int(mnist.train.num_examples / batch_size)\n",
        "    for i in range(total_batch):\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(batch_size=batch_size)\n",
        "        feed_dict = {x:batch_xs, y:batch_ys}\n",
        "        sess.run(optimizer, feed_dict=feed_dict)\n",
        "        avg_cost += sess.run(cost, feed_dict=feed_dict)\n",
        "    avg_cost = avg_cost / total_batch # epoch당 cost 평균\n",
        "    # Display\n",
        "    if (epoch+1) % display_step == 0:\n",
        "        print(\"Epoch: %03d/%03d cost: %.9f\" % (epoch, training_epochs, avg_cost))\n",
        "        feed_dict = {x: batch_xs, y: batch_ys}\n",
        "        train_acc = sess.run(accuracy, feed_dict=feed_dict)\n",
        "        print(\"Train Accuracy: %.3f\" % (train_acc))\n",
        "        feed_dict = {x: mnist.test.images, y: mnist.test.labels}\n",
        "        test_acc = sess.run(accuracy, feed_dict=feed_dict)\n",
        "        print(\"Test Accuracy: %.3f\" % (test_acc))\n",
        "        \n",
        "print(\"Optimizing Finished!!\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 003/020 cost: 0.343062357\n",
            "Train Accuracy: 0.860\n",
            "Test Accuracy: 0.907\n",
            "Epoch: 007/020 cost: 0.257410746\n",
            "Train Accuracy: 0.900\n",
            "Test Accuracy: 0.927\n",
            "Epoch: 011/020 cost: 0.213460426\n",
            "Train Accuracy: 0.970\n",
            "Test Accuracy: 0.936\n",
            "Epoch: 015/020 cost: 0.180081913\n",
            "Train Accuracy: 0.950\n",
            "Test Accuracy: 0.944\n",
            "Epoch: 019/020 cost: 0.153539784\n",
            "Train Accuracy: 0.950\n",
            "Test Accuracy: 0.950\n",
            "Optimizing Finished!!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}