{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_estimator_linearmodel.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Junhojuno/DeepLearning-Beginning/blob/master/tf_estimator_linearmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMmuEESIWp99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.feature_column as fc\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0MRIMv7XDLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz8TDHJDXWmm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "3af8564c-d407-4ba8-88f8-d676ee07a2d0"
      },
      "source": [
        "!pip install -q requests\n",
        "!git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 3168, done.\u001b[K\n",
            "remote: Counting objects: 100% (3168/3168), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2682/2682), done.\u001b[K\n",
            "remote: Total 3168 (delta 573), reused 2075 (delta 408), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3168/3168), 370.56 MiB | 40.54 MiB/s, done.\n",
            "Resolving deltas: 100% (573/573), done.\n",
            "Checking out files: 100% (2998/2998), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_yx7HtuXedK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add the root directory of the repo to your python path\n",
        "models_path = os.path.join(os.getcwd(), 'models')\n",
        "sys.path.append(models_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6lqv0HjX3C8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "5bc064e2-26b2-44a4-db09-56960d7bb346"
      },
      "source": [
        "# download the dataset\n",
        "from official.wide_deep import census_dataset, census_main\n",
        "census_dataset.download(\"/tmp/census_data/\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0618 02:17:59.553497 140493422073728 deprecation_wrapper.py:119] From /content/models/official/wide_deep/census_dataset.py:78: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0618 02:17:59.555037 140493422073728 deprecation_wrapper.py:119] From /content/models/official/wide_deep/census_dataset.py:81: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
            "\n",
            "W0618 02:18:00.228131 140493422073728 deprecation_wrapper.py:119] From /content/models/official/wide_deep/census_dataset.py:62: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0618 02:18:00.459901 140493422073728 deprecation_wrapper.py:119] From /content/models/official/wide_deep/census_dataset.py:73: The name tf.gfile.Remove is deprecated. Please use tf.io.gfile.remove instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_wjbpPxYHMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for using in Command line\n",
        "if 'PYTHONPATH' in os.environ:\n",
        "    os.environ['PYTHONPATH'] += os.pathsep + models_path\n",
        "else:\n",
        "    os.environ['PYTHONPATH'] = models_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3-Wv35GYmdN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1025
        },
        "outputId": "fea9164c-66f2-4bbe-efec-9b008b463926"
      },
      "source": [
        "# Use --help to see what command line options are available:\n",
        "!python -m official.wide_deep.census_main --help"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0618 02:20:33.613071 140282108643200 deprecation_wrapper.py:119] From /content/models/official/wide_deep/census_main.py:114: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0618 02:20:33.613363 140282108643200 deprecation_wrapper.py:119] From /content/models/official/wide_deep/census_main.py:114: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "Train DNN on census income dataset.\n",
            "flags:\n",
            "\n",
            "/content/models/official/wide_deep/census_main.py:\n",
            "  -bs,--batch_size:\n",
            "    Batch size for training and evaluation. When using multiple gpus, this is\n",
            "    the\n",
            "    global batch size for all devices. For example, if the batch size is 32 and\n",
            "    there are 4 GPUs, each GPU will get 8 examples on each step.\n",
            "    (default: '40')\n",
            "    (an integer)\n",
            "  --[no]clean:\n",
            "    If set, model_dir will be removed if it exists.\n",
            "    (default: 'false')\n",
            "  -dd,--data_dir:\n",
            "    The location of the input data.\n",
            "    (default: '/tmp/census_data')\n",
            "  --[no]download_if_missing:\n",
            "    Download data to data_dir if it is not already present.\n",
            "    (default: 'true')\n",
            "  -ebe,--epochs_between_evals:\n",
            "    The number of training epochs to run between evaluations.\n",
            "    (default: '2')\n",
            "    (an integer)\n",
            "  -ed,--export_dir:\n",
            "    If set, a SavedModel serialization of the model will be exported to this\n",
            "    directory at the end of training. See the README for more details and\n",
            "    relevant\n",
            "    links.\n",
            "  -hk,--hooks:\n",
            "    A list of (case insensitive) strings to specify the names of training hooks.\n",
            "    ﻿  Hook:\n",
            "    ﻿    loggingtensorhook\n",
            "    ﻿    profilerhook\n",
            "    ﻿    examplespersecondhook\n",
            "    ﻿    loggingmetrichook\n",
            "    ﻿  Example: `--hooks ProfilerHook,ExamplesPerSecondHook`\n",
            "    See official.utils.logs.hooks_helper for details.\n",
            "    (default: 'LoggingTensorHook')\n",
            "    (a comma separated list)\n",
            "  -md,--model_dir:\n",
            "    The location of the model checkpoint files.\n",
            "    (default: '/tmp/census_model')\n",
            "  -mt,--model_type: <wide|deep|wide_deep>: Select model topology.\n",
            "    (default: 'wide_deep')\n",
            "  -te,--train_epochs:\n",
            "    The number of epochs used to train.\n",
            "    (default: '40')\n",
            "    (an integer)\n",
            "\n",
            "Try --helpfull to get a list of all flags.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ8yeCVCYsMH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3043
        },
        "outputId": "31503f62-a152-4537-8197-0c44ed321f73"
      },
      "source": [
        "# run model\n",
        "!python -m official.wide_deep.census_main --model_type=wide --train_epochs=2"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0618 02:21:41.690503 140374330308480 deprecation_wrapper.py:119] From /content/models/official/wide_deep/census_main.py:114: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0618 02:21:41.690805 140374330308480 deprecation_wrapper.py:119] From /content/models/official/wide_deep/census_main.py:114: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0618 02:21:41.693827 140374330308480 deprecation_wrapper.py:119] From /content/models/official/wide_deep/census_dataset.py:78: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0618 02:21:41.694007 140374330308480 deprecation_wrapper.py:119] From /content/models/official/wide_deep/census_dataset.py:81: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
            "\n",
            "W0618 02:21:41.694878 140374330308480 deprecation_wrapper.py:119] From /content/models/official/wide_deep/census_main.py:49: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "I0618 02:21:41.695704 140374330308480 estimator.py:209] Using config: {'_model_dir': '/tmp/census_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': device_count {\n",
            "  key: \"GPU\"\n",
            "  value: 0\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fab375045f8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "W0618 02:21:41.696815 140374330308480 logger.py:391] 'cpuinfo' not imported. CPU info will not be logged.\n",
            "2019-06-18 02:21:41.745614: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-06-18 02:21:41.749830: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x265ad80 executing computations on platform Host. Devices:\n",
            "2019-06-18 02:21:41.749868: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-06-18 02:21:41.755555: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-06-18 02:21:42.003599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-06-18 02:21:42.004149: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x265b9c0 executing computations on platform CUDA. Devices:\n",
            "2019-06-18 02:21:42.004179: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2019-06-18 02:21:42.004397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-06-18 02:21:42.004799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-06-18 02:21:42.021662: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-06-18 02:21:42.191784: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-06-18 02:21:42.268323: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-06-18 02:21:42.295403: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-06-18 02:21:42.494979: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-06-18 02:21:42.623572: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-06-18 02:21:42.969422: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-06-18 02:21:42.969626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-06-18 02:21:42.970163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-06-18 02:21:42.970542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-06-18 02:21:42.972954: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-06-18 02:21:42.974925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-06-18 02:21:42.974959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-06-18 02:21:42.974982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-06-18 02:21:42.982266: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-06-18 02:21:42.982774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-06-18 02:21:42.983156: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-06-18 02:21:42.983206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "I0618 02:21:48.031453 140374330308480 logger.py:152] Benchmark run: {'model_name': 'wide_deep', 'dataset': {'name': 'Census Income'}, 'machine_config': {'gpu_info': {'count': 1, 'model': 'Tesla T4'}, 'memory_total': 13655322624, 'memory_available': 12568748032}, 'test_id': None, 'run_date': '2019-06-18T02:21:41.696408Z', 'tensorflow_version': {'version': '1.14.0-rc1', 'git_hash': 'v1.14.0-rc1-0-g648ea74ea0'}, 'tensorflow_environment_variables': [{'name': 'TF_FORCE_GPU_ALLOW_GROWTH', 'value': 'true'}], 'run_parameters': [{'name': 'batch_size', 'long_value': 40}, {'name': 'model_type', 'string_value': 'wide'}, {'name': 'train_epochs', 'long_value': 2}]}\n",
            "W0618 02:21:48.042725 140374330308480 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0618 02:21:48.071355 140374330308480 deprecation_wrapper.py:119] From /content/models/official/wide_deep/census_dataset.py:167: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "I0618 02:21:48.071504 140374330308480 census_dataset.py:167] Parsing /tmp/census_data/adult.data\n",
            "W0618 02:21:48.071606 140374330308480 deprecation_wrapper.py:119] From /content/models/official/wide_deep/census_dataset.py:168: The name tf.decode_csv is deprecated. Please use tf.io.decode_csv instead.\n",
            "\n",
            "I0618 02:21:48.113370 140374330308480 estimator.py:1145] Calling model_fn.\n",
            "W0618 02:21:48.467810 140374330308480 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/sparse_ops.py:1719: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0618 02:21:48.932053 140374330308480 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/linear.py:308: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "I0618 02:21:49.631353 140374330308480 estimator.py:1147] Done calling model_fn.\n",
            "I0618 02:21:49.631717 140374330308480 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "I0618 02:21:50.034778 140374330308480 monitored_session.py:240] Graph was finalized.\n",
            "2019-06-18 02:21:50.035308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-06-18 02:21:50.035351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      \n",
            "2019-06-18 02:21:50.127599: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "I0618 02:21:50.179698 140374330308480 session_manager.py:500] Running local_init_op.\n",
            "I0618 02:21:50.201351 140374330308480 session_manager.py:502] Done running local_init_op.\n",
            "I0618 02:21:50.972360 140374330308480 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /tmp/census_model/model.ckpt.\n",
            "I0618 02:21:51.833827 140374330308480 basic_session_run_hooks.py:262] average_loss = 0.6931472, loss = 27.725887\n",
            "I0618 02:21:51.834183 140374330308480 basic_session_run_hooks.py:262] loss = 27.725887, step = 1\n",
            "I0618 02:21:52.429172 140374330308480 basic_session_run_hooks.py:692] global_step/sec: 167.844\n",
            "I0618 02:21:52.429909 140374330308480 basic_session_run_hooks.py:260] average_loss = 0.2580979, loss = 10.3239155 (0.596 sec)\n",
            "I0618 02:21:52.430119 140374330308480 basic_session_run_hooks.py:260] loss = 10.3239155, step = 101 (0.596 sec)\n",
            "I0618 02:21:52.714958 140374330308480 basic_session_run_hooks.py:692] global_step/sec: 349.949\n",
            "I0618 02:21:52.715568 140374330308480 basic_session_run_hooks.py:260] average_loss = 0.3234958, loss = 12.939833 (0.286 sec)\n",
            "I0618 02:21:52.715775 140374330308480 basic_session_run_hooks.py:260] loss = 12.939833, step = 201 (0.286 sec)\n",
            "I0618 02:21:52.976084 140374330308480 basic_session_run_hooks.py:692] global_step/sec: 382.923\n",
            "I0618 02:21:52.976797 140374330308480 basic_session_run_hooks.py:260] average_loss = 0.25078636, loss = 10.031454 (0.261 sec)\n",
            "I0618 02:21:52.977014 140374330308480 basic_session_run_hooks.py:260] loss = 10.031454, step = 301 (0.261 sec)\n",
            "I0618 02:21:53.265064 140374330308480 basic_session_run_hooks.py:692] global_step/sec: 346.046\n",
            "I0618 02:21:53.265777 140374330308480 basic_session_run_hooks.py:260] average_loss = 0.30604935, loss = 12.241974 (0.289 sec)\n",
            "I0618 02:21:53.266076 140374330308480 basic_session_run_hooks.py:260] loss = 12.241974, step = 401 (0.289 sec)\n",
            "I0618 02:21:53.553257 140374330308480 basic_session_run_hooks.py:692] global_step/sec: 347.029\n",
            "I0618 02:21:53.554040 140374330308480 basic_session_run_hooks.py:260] average_loss = 0.24040127, loss = 9.616051 (0.288 sec)\n",
            "I0618 02:21:53.554281 140374330308480 basic_session_run_hooks.py:260] loss = 9.616051, step = 501 (0.288 sec)\n",
            "I0618 02:21:53.835034 140374330308480 basic_session_run_hooks.py:692] global_step/sec: 354.829\n",
            "I0618 02:21:53.835660 140374330308480 basic_session_run_hooks.py:260] average_loss = 0.26537886, loss = 10.615154 (0.282 sec)\n",
            "I0618 02:21:53.835870 140374330308480 basic_session_run_hooks.py:260] loss = 10.615154, step = 601 (0.282 sec)\n",
            "I0618 02:21:54.097162 140374330308480 basic_session_run_hooks.py:692] global_step/sec: 381.521\n",
            "I0618 02:21:54.097899 140374330308480 basic_session_run_hooks.py:260] average_loss = 0.34397393, loss = 13.758957 (0.262 sec)\n",
            "I0618 02:21:54.098104 140374330308480 basic_session_run_hooks.py:260] loss = 13.758957, step = 701 (0.262 sec)\n",
            "I0618 02:21:54.369472 140374330308480 basic_session_run_hooks.py:692] global_step/sec: 367.241\n",
            "I0618 02:21:54.370166 140374330308480 basic_session_run_hooks.py:260] average_loss = 0.40742293, loss = 16.296917 (0.272 sec)\n",
            "I0618 02:21:54.370376 140374330308480 basic_session_run_hooks.py:260] loss = 16.296917, step = 801 (0.272 sec)\n",
            "I0618 02:21:54.708876 140374330308480 basic_session_run_hooks.py:692] global_step/sec: 294.645\n",
            "I0618 02:21:54.710653 140374330308480 basic_session_run_hooks.py:260] average_loss = 0.30915707, loss = 12.366283 (0.340 sec)\n",
            "I0618 02:21:54.711043 140374330308480 basic_session_run_hooks.py:260] loss = 12.366283, step = 901 (0.341 sec)\n",
            "I0618 02:21:54.984972 140374330308480 basic_session_run_hooks.py:692] global_step/sec: 362.167\n",
            "I0618 02:21:54.985655 140374330308480 basic_session_run_hooks.py:260] average_loss = 0.39361295, loss = 15.744518 (0.275 sec)\n",
            "I0618 02:21:54.985872 140374330308480 basic_session_run_hooks.py:260] loss = 15.744518, step = 1001 (0.275 sec)\n",
            "I0618 02:21:55.254609 140374330308480 basic_session_run_hooks.py:692] global_step/sec: 370.86\n",
            "I0618 02:21:55.255295 140374330308480 basic_session_run_hooks.py:260] average_loss = 0.5208241, loss = 20.832962 (0.270 sec)\n",
            "I0618 02:21:55.255553 140374330308480 basic_session_run_hooks.py:260] loss = 20.832962, step = 1101 (0.270 sec)\n",
            "I0618 02:21:55.522802 140374330308480 basic_session_run_hooks.py:692] global_step/sec: 372.883\n",
            "I0618 02:21:55.523541 140374330308480 basic_session_run_hooks.py:260] average_loss = 0.28922597, loss = 11.569038 (0.268 sec)\n",
            "I0618 02:21:55.523917 140374330308480 basic_session_run_hooks.py:260] loss = 11.569038, step = 1201 (0.268 sec)\n",
            "I0618 02:21:55.802838 140374330308480 basic_session_run_hooks.py:692] global_step/sec: 357.082\n",
            "I0618 02:21:55.803584 140374330308480 basic_session_run_hooks.py:260] average_loss = 0.24933887, loss = 9.973555 (0.280 sec)\n",
            "I0618 02:21:55.803913 140374330308480 basic_session_run_hooks.py:260] loss = 9.973555, step = 1301 (0.280 sec)\n",
            "I0618 02:21:56.076504 140374330308480 basic_session_run_hooks.py:692] global_step/sec: 365.433\n",
            "I0618 02:21:56.077114 140374330308480 basic_session_run_hooks.py:260] average_loss = 0.38473326, loss = 15.38933 (0.274 sec)\n",
            "I0618 02:21:56.077326 140374330308480 basic_session_run_hooks.py:260] loss = 15.38933, step = 1401 (0.273 sec)\n",
            "I0618 02:21:56.357172 140374330308480 basic_session_run_hooks.py:692] global_step/sec: 356.265\n",
            "I0618 02:21:56.357934 140374330308480 basic_session_run_hooks.py:260] average_loss = 0.31031436, loss = 12.412575 (0.281 sec)\n",
            "I0618 02:21:56.358235 140374330308480 basic_session_run_hooks.py:260] loss = 12.412575, step = 1501 (0.281 sec)\n",
            "I0618 02:21:56.628048 140374330308480 basic_session_run_hooks.py:692] global_step/sec: 369.168\n",
            "I0618 02:21:56.628675 140374330308480 basic_session_run_hooks.py:260] average_loss = 0.32551187, loss = 13.020475 (0.271 sec)\n",
            "I0618 02:21:56.628884 140374330308480 basic_session_run_hooks.py:260] loss = 13.020475, step = 1601 (0.271 sec)\n",
            "I0618 02:21:56.722892 140374330308480 basic_session_run_hooks.py:606] Saving checkpoints for 1629 into /tmp/census_model/model.ckpt.\n",
            "I0618 02:21:56.881346 140374330308480 estimator.py:368] Loss for final step: 0.33970028.\n",
            "I0618 02:21:56.905838 140374330308480 census_dataset.py:167] Parsing /tmp/census_data/adult.test\n",
            "I0618 02:21:56.941754 140374330308480 estimator.py:1145] Calling model_fn.\n",
            "W0618 02:21:57.855187 140374330308480 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:2027: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "W0618 02:21:58.352527 140374330308480 metrics_impl.py:804] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
            "W0618 02:21:58.373770 140374330308480 metrics_impl.py:804] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
            "I0618 02:21:58.396237 140374330308480 estimator.py:1147] Done calling model_fn.\n",
            "I0618 02:21:58.416667 140374330308480 evaluation.py:255] Starting evaluation at 2019-06-18T02:21:58Z\n",
            "I0618 02:21:58.550940 140374330308480 monitored_session.py:240] Graph was finalized.\n",
            "2019-06-18 02:21:58.551406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-06-18 02:21:58.551464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      \n",
            "W0618 02:21:58.551583 140374330308480 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "I0618 02:21:58.552948 140374330308480 saver.py:1280] Restoring parameters from /tmp/census_model/model.ckpt-1629\n",
            "I0618 02:21:58.651469 140374330308480 session_manager.py:500] Running local_init_op.\n",
            "I0618 02:21:58.698924 140374330308480 session_manager.py:502] Done running local_init_op.\n",
            "I0618 02:22:00.488134 140374330308480 evaluation.py:275] Finished evaluation at 2019-06-18-02:22:00\n",
            "I0618 02:22:00.488391 140374330308480 estimator.py:2039] Saving dict for global step 1629: accuracy = 0.8360666, accuracy_baseline = 0.76377374, auc = 0.88413656, auc_precision_recall = 0.6953496, average_loss = 0.3516626, global_step = 1629, label/mean = 0.23622628, loss = 14.032889, precision = 0.70412767, prediction/mean = 0.22265631, recall = 0.5278211\n",
            "I0618 02:22:00.725699 140374330308480 estimator.py:2099] Saving 'checkpoint_path' summary for global step 1629: /tmp/census_model/model.ckpt-1629\n",
            "I0618 02:22:00.726319 140374330308480 wide_deep_run_loop.py:116] Results at epoch 2 / 2\n",
            "I0618 02:22:00.726489 140374330308480 wide_deep_run_loop.py:117] ------------------------------------------------------------\n",
            "I0618 02:22:00.726589 140374330308480 wide_deep_run_loop.py:120] accuracy: 0.8360666\n",
            "I0618 02:22:00.726665 140374330308480 wide_deep_run_loop.py:120] accuracy_baseline: 0.76377374\n",
            "I0618 02:22:00.726736 140374330308480 wide_deep_run_loop.py:120] auc: 0.88413656\n",
            "I0618 02:22:00.726807 140374330308480 wide_deep_run_loop.py:120] auc_precision_recall: 0.6953496\n",
            "I0618 02:22:00.726878 140374330308480 wide_deep_run_loop.py:120] average_loss: 0.3516626\n",
            "I0618 02:22:00.726952 140374330308480 wide_deep_run_loop.py:120] global_step: 1629\n",
            "I0618 02:22:00.727018 140374330308480 wide_deep_run_loop.py:120] label/mean: 0.23622628\n",
            "I0618 02:22:00.727084 140374330308480 wide_deep_run_loop.py:120] loss: 14.032889\n",
            "I0618 02:22:00.727148 140374330308480 wide_deep_run_loop.py:120] precision: 0.70412767\n",
            "I0618 02:22:00.727212 140374330308480 wide_deep_run_loop.py:120] prediction/mean: 0.22265631\n",
            "I0618 02:22:00.727276 140374330308480 wide_deep_run_loop.py:120] recall: 0.5278211\n",
            "I0618 02:22:00.727462 140374330308480 logger.py:147] Benchmark metric: {'name': 'accuracy', 'value': 0.8360666036605835, 'unit': None, 'global_step': 1629, 'timestamp': '2019-06-18T02:22:00.727405Z', 'extras': []}\n",
            "I0618 02:22:00.727608 140374330308480 logger.py:147] Benchmark metric: {'name': 'accuracy_baseline', 'value': 0.7637737393379211, 'unit': None, 'global_step': 1629, 'timestamp': '2019-06-18T02:22:00.727583Z', 'extras': []}\n",
            "I0618 02:22:00.727721 140374330308480 logger.py:147] Benchmark metric: {'name': 'auc', 'value': 0.8841365575790405, 'unit': None, 'global_step': 1629, 'timestamp': '2019-06-18T02:22:00.727697Z', 'extras': []}\n",
            "I0618 02:22:00.727825 140374330308480 logger.py:147] Benchmark metric: {'name': 'auc_precision_recall', 'value': 0.6953495740890503, 'unit': None, 'global_step': 1629, 'timestamp': '2019-06-18T02:22:00.727801Z', 'extras': []}\n",
            "I0618 02:22:00.727926 140374330308480 logger.py:147] Benchmark metric: {'name': 'average_loss', 'value': 0.35166260600090027, 'unit': None, 'global_step': 1629, 'timestamp': '2019-06-18T02:22:00.727903Z', 'extras': []}\n",
            "I0618 02:22:00.728036 140374330308480 logger.py:147] Benchmark metric: {'name': 'label/mean', 'value': 0.23622627556324005, 'unit': None, 'global_step': 1629, 'timestamp': '2019-06-18T02:22:00.728012Z', 'extras': []}\n",
            "I0618 02:22:00.728146 140374330308480 logger.py:147] Benchmark metric: {'name': 'loss', 'value': 14.032889366149902, 'unit': None, 'global_step': 1629, 'timestamp': '2019-06-18T02:22:00.728122Z', 'extras': []}\n",
            "I0618 02:22:00.728249 140374330308480 logger.py:147] Benchmark metric: {'name': 'precision', 'value': 0.7041276693344116, 'unit': None, 'global_step': 1629, 'timestamp': '2019-06-18T02:22:00.728227Z', 'extras': []}\n",
            "I0618 02:22:00.728351 140374330308480 logger.py:147] Benchmark metric: {'name': 'prediction/mean', 'value': 0.22265630960464478, 'unit': None, 'global_step': 1629, 'timestamp': '2019-06-18T02:22:00.728329Z', 'extras': []}\n",
            "I0618 02:22:00.728468 140374330308480 logger.py:147] Benchmark metric: {'name': 'recall', 'value': 0.5278211236000061, 'unit': None, 'global_step': 1629, 'timestamp': '2019-06-18T02:22:00.728445Z', 'extras': []}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-fdYC-rY80Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a562730f-e9e9-4fa6-aca3-859dea390f0d"
      },
      "source": [
        "# Read US census data\n",
        "!ls /tmp/census_data/"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adult.data  adult.test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt7tzDOWZTbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file = '/tmp/census_data/adult.data'\n",
        "test_file = '/tmp/census_data/adult.test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFh3vA-aZpoi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2ae68f39-3647-4f7c-8dfa-2319b7bfd58e"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv(train_file, names=census_dataset._CSV_COLUMNS)\n",
        "test_df = pd.read_csv(test_file, names=census_dataset._CSV_COLUMNS)\n",
        "\n",
        "train_df.tail()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>native_country</th>\n",
              "      <th>income_bracket</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>32556</th>\n",
              "      <td>27</td>\n",
              "      <td>Private</td>\n",
              "      <td>257302</td>\n",
              "      <td>Assoc-acdm</td>\n",
              "      <td>12</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Tech-support</td>\n",
              "      <td>Wife</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32557</th>\n",
              "      <td>40</td>\n",
              "      <td>Private</td>\n",
              "      <td>154374</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32558</th>\n",
              "      <td>58</td>\n",
              "      <td>Private</td>\n",
              "      <td>151910</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Widowed</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32559</th>\n",
              "      <td>22</td>\n",
              "      <td>Private</td>\n",
              "      <td>201490</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32560</th>\n",
              "      <td>52</td>\n",
              "      <td>Self-emp-inc</td>\n",
              "      <td>287927</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Wife</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>15024</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       age     workclass  fnlwgt  ... hours_per_week  native_country income_bracket\n",
              "32556   27       Private  257302  ...             38   United-States          <=50K\n",
              "32557   40       Private  154374  ...             40   United-States           >50K\n",
              "32558   58       Private  151910  ...             40   United-States          <=50K\n",
              "32559   22       Private  201490  ...             20   United-States          <=50K\n",
              "32560   52  Self-emp-inc  287927  ...             40   United-States           >50K\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKNmqDX7aRJ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "acbedd26-efa2-4707-f24c-8365e25a38ed"
      },
      "source": [
        "# 위에서 eager execution enable했기 때문에 쉽게 데이터셋 보기 가능\n",
        "# tf.data.Dataset으로 slicing하는건 데이터가 작기때문에 가능\n",
        "def easy_input_function(df, label_key, num_epochs, shuffle, batch_size):\n",
        "  label = df[label_key]\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(df),label))\n",
        "\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(10000)\n",
        "\n",
        "  ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "\n",
        "  return ds\n",
        "\n",
        "ds = easy_input_function(train_df, label_key='income_bracket', num_epochs=5, shuffle=True, batch_size=10)\n",
        "\n",
        "for feature_batch, label_batch in ds.take(1):\n",
        "  print('Some feature keys:', list(feature_batch.keys())[:5])\n",
        "  print()\n",
        "  print('A batch of Ages  :', feature_batch['age'])\n",
        "  print()\n",
        "  print('A batch of Labels:', label_batch )"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some feature keys: ['age', 'workclass', 'fnlwgt', 'education', 'education_num']\n",
            "\n",
            "A batch of Ages  : tf.Tensor([22 33 23 36 45 18 41 53 45 27], shape=(10,), dtype=int32)\n",
            "\n",
            "A batch of Labels: tf.Tensor(\n",
            "[b'<=50K' b'>50K' b'<=50K' b'>50K' b'<=50K' b'<=50K' b'<=50K' b'>50K'\n",
            " b'<=50K' b'<=50K'], shape=(10,), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsbquKvRatGH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "outputId": "131e982f-6f1d-487e-9569-995da830d555"
      },
      "source": [
        "# 데이터가 커지면....tf.decode_csv와 tf.data.TextLineDataset를 사용한다. (이 둘을 사용한게 input_fn)\n",
        "# 위와 같은 결과가 나온다.\n",
        "# input_fn을 사용하여 batch와 epochs를 지정하여 계속 뽑을 수 있다.\n",
        "import inspect\n",
        "print(inspect.getsource(census_dataset.input_fn))\n",
        "\n",
        "ds = census_dataset.input_fn(train_file, num_epochs=5, shuffle=True, batch_size=10)\n",
        "\n",
        "for feature_batch, label_batch in ds.take(1):\n",
        "  print('Feature keys:', list(feature_batch.keys())[:5])\n",
        "  print()\n",
        "  print('Age batch   :', feature_batch['age'])\n",
        "  print()\n",
        "  print('Label batch :', label_batch )"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def input_fn(data_file, num_epochs, shuffle, batch_size):\n",
            "  \"\"\"Generate an input function for the Estimator.\"\"\"\n",
            "  assert tf.gfile.Exists(data_file), (\n",
            "      '%s not found. Please make sure you have run census_dataset.py and '\n",
            "      'set the --data_dir argument to the correct path.' % data_file)\n",
            "\n",
            "  def parse_csv(value):\n",
            "    tf.logging.info('Parsing {}'.format(data_file))\n",
            "    columns = tf.decode_csv(value, record_defaults=_CSV_COLUMN_DEFAULTS)\n",
            "    features = dict(zip(_CSV_COLUMNS, columns))\n",
            "    labels = features.pop('income_bracket')\n",
            "    classes = tf.equal(labels, '>50K')  # binary classification\n",
            "    return features, classes\n",
            "\n",
            "  # Extract lines from input files using the Dataset API.\n",
            "  dataset = tf.data.TextLineDataset(data_file)\n",
            "\n",
            "  if shuffle:\n",
            "    dataset = dataset.shuffle(buffer_size=_NUM_EXAMPLES['train'])\n",
            "\n",
            "  dataset = dataset.map(parse_csv, num_parallel_calls=5)\n",
            "\n",
            "  # We call repeat after shuffling, rather than before, to prevent separate\n",
            "  # epochs from blending together.\n",
            "  dataset = dataset.repeat(num_epochs)\n",
            "  dataset = dataset.batch(batch_size)\n",
            "  return dataset\n",
            "\n",
            "Feature keys: ['age', 'workclass', 'fnlwgt', 'education', 'education_num']\n",
            "\n",
            "Age batch   : tf.Tensor([22 44 48 68 39 37 56 42 28 18], shape=(10,), dtype=int32)\n",
            "\n",
            "Label batch : tf.Tensor([False  True  True  True  True  True False  True False False], shape=(10,), dtype=bool)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCSzFdwtbWJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Because Estimators expect an input_fn that takes no arguments, \n",
        "# we typically wrap configurable input function into an obejct with the expected signature. \n",
        "# For this notebook configure the train_inpf to iterate over the data twice:\n",
        "import functools\n",
        "\n",
        "train_inpf = functools.partial(census_dataset.input_fn, train_file, num_epochs=2, shuffle=True, batch_size=64)\n",
        "test_inpf = functools.partial(census_dataset.input_fn, test_file, num_epochs=1, shuffle=False, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vrO_XVMcBU2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "dadc037c-d855-42de-bac9-6c46da1b5bef"
      },
      "source": [
        "# model only using a column\n",
        "classifier = tf.estimator.LinearClassifier(feature_columns=[fc.numeric_column('age')])\n",
        "classifier.train(train_inpf)\n",
        "result = classifier.evaluate(test_inpf)\n",
        "\n",
        "clear_output()\n",
        "print(result)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'accuracy': 0.7590443, 'accuracy_baseline': 0.76377374, 'auc': 0.67830986, 'auc_precision_recall': 0.31138018, 'average_loss': 0.52304345, 'label/mean': 0.23622628, 'loss': 33.394787, 'precision': 0.14678898, 'prediction/mean': 0.2417537, 'recall': 0.0041601663, 'global_step': 1018}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrdzpCRrcVIK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "a3777b42-daaf-4ed7-f9e6-0f806b0f8f08"
      },
      "source": [
        "# Similarly, we can define a NumericColumn for each continuous feature column that we want to use in the model:\n",
        "# 이런식으로 numerical columns들만 뽑을 수도 있음.\n",
        "age = fc.numeric_column('age')\n",
        "education_num = tf.feature_column.numeric_column('education_num')\n",
        "capital_gain = tf.feature_column.numeric_column('capital_gain')\n",
        "capital_loss = tf.feature_column.numeric_column('capital_loss')\n",
        "hours_per_week = tf.feature_column.numeric_column('hours_per_week')\n",
        "\n",
        "my_numeric_columns = [age,education_num, capital_gain, capital_loss, hours_per_week]\n",
        "\n",
        "fc.input_layer(feature_batch, my_numeric_columns).numpy()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0618 02:44:06.778625 140493422073728 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:205: NumericColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "W0618 02:44:06.781412 140493422073728 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:2115: NumericColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "W0618 02:44:06.785332 140493422073728 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:206: NumericColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[27.,  0.,  0., 11., 40.],\n",
              "       [29.,  0.,  0.,  6., 40.],\n",
              "       [22.,  0.,  0., 11., 75.],\n",
              "       [34.,  0.,  0., 10., 40.],\n",
              "       [38.,  0.,  0.,  9., 40.],\n",
              "       [45.,  0.,  0.,  9., 40.],\n",
              "       [24.,  0.,  0., 10., 40.],\n",
              "       [38.,  0.,  0., 13., 40.],\n",
              "       [40.,  0.,  0., 11., 40.],\n",
              "       [34.,  0.,  0., 12., 50.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kvy-fazCeF2P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "62ad29ad-0fd5-497a-ced4-3b91327883d5"
      },
      "source": [
        "classifier = tf.estimator.LinearClassifier(feature_columns=my_numeric_columns)\n",
        "classifier.train(train_inpf)\n",
        "\n",
        "result = classifier.evaluate(test_inpf)\n",
        "\n",
        "clear_output()\n",
        "\n",
        "for key,value in sorted(result.items()):\n",
        "  print('%s: %s' % (key, value))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.78250724\n",
            "accuracy_baseline: 0.76377374\n",
            "auc: 0.71121407\n",
            "auc_precision_recall: 0.5095864\n",
            "average_loss: 7.3911877\n",
            "global_step: 1018\n",
            "label/mean: 0.23622628\n",
            "loss: 471.9056\n",
            "precision: 0.61526835\n",
            "prediction/mean: 0.26402935\n",
            "recall: 0.21164846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W1htEAPeK4I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "outputId": "647d9ddc-6375-4d44-9709-67112cf768e2"
      },
      "source": [
        "# categorical columns들에 대해선...\n",
        "# 다음과 같이 뽑을 수 있음.\n",
        "relationship = fc.categorical_column_with_vocabulary_list(\n",
        "    'relationship',\n",
        "    ['Husband', 'Not-in-family', 'Wife', 'Own-child', 'Unmarried', 'Other-relative'])\n",
        "\n",
        "fc.input_layer(feature_batch, [age, fc.indicator_column(relationship)])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0618 02:49:16.828300 140493422073728 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:205: IndicatorColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "W0618 02:49:16.831818 140493422073728 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:2115: IndicatorColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "W0618 02:49:16.835200 140493422073728 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4236: VocabularyListCategoricalColumn._get_sparse_tensors (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "W0618 02:49:16.838194 140493422073728 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:2115: VocabularyListCategoricalColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "W0618 02:49:16.846775 140493422073728 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4207: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "W0618 02:49:16.847798 140493422073728 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4262: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=5182, shape=(10, 7), dtype=float32, numpy=\n",
              "array([[22.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
              "       [44.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
              "       [48.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
              "       [68.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
              "       [39.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
              "       [37.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
              "       [56.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
              "       [42.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
              "       [28.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
              "       [18.,  0.,  0.,  0.,  1.,  0.,  0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL4_7bbQfRhO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "ea7a994a-8109-4219-ba55-acb46171e2d5"
      },
      "source": [
        "# 위는 category갯수를 아는 경우에 해당되고,\n",
        "# 모를 땐 다음을 활용한다. categorical_column_with_hash_bucket\n",
        "occupation = tf.feature_column.categorical_column_with_hash_bucket(\n",
        "    'occupation', hash_bucket_size=1000)\n",
        "\n",
        "for item in feature_batch['occupation'].numpy():\n",
        "    print(item.decode())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Priv-house-serv\n",
            "Exec-managerial\n",
            "Adm-clerical\n",
            "?\n",
            "Exec-managerial\n",
            "Transport-moving\n",
            "Adm-clerical\n",
            "Craft-repair\n",
            "Craft-repair\n",
            "Sales\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgPKX_-VfnC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "education = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "    'education', [\n",
        "        'Bachelors', 'HS-grad', '11th', 'Masters', '9th', 'Some-college',\n",
        "        'Assoc-acdm', 'Assoc-voc', '7th-8th', 'Doctorate', 'Prof-school',\n",
        "        '5th-6th', '10th', '1st-4th', 'Preschool', '12th'])\n",
        "\n",
        "marital_status = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "    'marital_status', [\n",
        "        'Married-civ-spouse', 'Divorced', 'Married-spouse-absent',\n",
        "        'Never-married', 'Separated', 'Married-AF-spouse', 'Widowed'])\n",
        "\n",
        "workclass = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "    'workclass', [\n",
        "        'Self-emp-not-inc', 'Private', 'State-gov', 'Federal-gov',\n",
        "        'Local-gov', '?', 'Self-emp-inc', 'Without-pay', 'Never-worked'])\n",
        "\n",
        "\n",
        "my_categorical_columns = [relationship, occupation, education, marital_status, workclass]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYfVxx09fx_8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "0eb3fcc8-330f-413d-fd8a-7b407a0c4d9b"
      },
      "source": [
        "classifier = tf.estimator.LinearClassifier(feature_columns=my_numeric_columns+my_categorical_columns)\n",
        "classifier.train(train_inpf)\n",
        "result = classifier.evaluate(test_inpf)\n",
        "\n",
        "clear_output()\n",
        "\n",
        "for key,value in sorted(result.items()):\n",
        "  print('%s: %s' % (key, value))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.82673055\n",
            "accuracy_baseline: 0.76377374\n",
            "auc: 0.87491494\n",
            "auc_precision_recall: 0.6558813\n",
            "average_loss: 1.6820824\n",
            "global_step: 1018\n",
            "label/mean: 0.23622628\n",
            "loss: 107.39602\n",
            "precision: 0.63922846\n",
            "prediction/mean: 0.25356495\n",
            "recall: 0.6118045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utx3gOmEfzzs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to be continue...."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}